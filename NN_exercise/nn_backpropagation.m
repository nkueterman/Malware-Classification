function [J,theta1,theta2] = nn_backpropagation(theta1,theta2,inputSize,nHidden,X,y,n,alpha)

% preprocess labels
yActual = ind2vec(y',inputSize);

%% Network computation

% variable preallocation (for speed)
J = zeros(1,n);

% iterations or epochs for gradient descent calculataion
for ix = 1:n
    
    % forward propagation
    z2 = theta1 * X';
    a2 = compute_sigmoid(z2);
    a2 = vertcat(ones(1,size(z2,2)), a2);
    z3 = theta2 * a2;
    h  = compute_sigmoid(z3);
    
    % backward propagation
    % calculate cost function with new weights
    % compute logistic regression cost
    J(1,n) = (-1/length(X))*sum(sum(yActual.*log(h)+(1-yActual).*log(1-h)));
    
    d3 = h - yActual;
    temp = compute_sigmoid(z2);
    temp = vertcat(ones(1,size(X,1)),temp);
    d2 = theta2' * d3 .* (temp .* (1 - temp));
    d2(1,:) = [];

    % compute new weights
    theta2 = theta2 - alpha *(d3 * a2')/size(X,1);
    theta1 = theta1 - alpha *(d2 * X)/size(X,1);
    
end

end

